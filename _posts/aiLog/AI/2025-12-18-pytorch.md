---
layout: post
related_posts:
  - /aiLog/ai
title:  "íŒŒì´í† ì¹˜(PyTorch) - ë¨¸ì‹ ëŸ¬ë‹"
date:   2025-12-18
categories:
  - ai
description: >
  
---
* toc
{:toc .large-only}

# PyTorch(íŒŒì´í† ì¹˜)

PyTorchëŠ” íŒŒì´ì¬ ê¸°ë°˜ì˜ ì˜¤í”ˆì†ŒìŠ¤ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¡œ, íŒŒì´ì¬ ì½”ë“œë¡œ AI ëª¨ë¸ì„ ì§ê´€ì ìœ¼ë¡œ ë§Œë“¤ê³  í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬ì´ë‹¤. íŠ¹íˆ **ë™ì  ê³„ì‚° ê·¸ë˜í”„ ë°©ì‹**ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì½”ë“œ ì‹¤í–‰ ì‹œì ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì‚° íë¦„ì´ ê²°ì •ë˜ì–´ ë””ë²„ê¹…ê³¼ ìˆ˜ì •ì´ ì‰½ê³ , **GPU ê°€ì†**ê³¼ **ìë™ ë¯¸ë¶„ ê¸°ëŠ¥**ì„ í†µí•´ ëŒ€ê·œëª¨ ëª¨ë¸ë„ ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.

```
pip install pytorch
```

## â€» ë™ì  ê³„ì‚° ê·¸ë˜í”„ ë°©ì‹

**ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ë•Œ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì‹¤í–‰ ì‹œì (runtime)ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„± ë° ìˆ˜ì •í•˜ëŠ” ë°©ì‹**ì´ë‹¤. ì´ ë°©ì‹ì€ ì¡°ê±´ë¬¸, ë°˜ë³µë¬¸ ë“± ë³µì¡í•œ ë…¼ë¦¬ êµ¬ì¡°ë¥¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ì£¼ë¡œ PyTorchì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ì—ì„œ ì‚¬ìš©ëœë‹¤. ê³„ì‚° ê·¸ë˜í”„ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©´ì„œ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³ , ì—­ì „íŒŒë¥¼ í†µí•´ ë¯¸ë¶„ì„ ê³„ì‚°í•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹œë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•ë¶„ì— ë””ë²„ê¹…ì´ ìš©ì´í•˜ê³  ì—°êµ¬ ë° ê°œë°œ ì†ë„ê°€ ë¹ ë¥´ë©° ì§ê´€ì ì¸ ì½”ë“œ ì‘ì„±ì´ ê°€ëŠ¥í•˜ë‹¤.

### ìŠ¤ì¹¼ë¼ (Scalar)

ìŠ¤ì¹¼ë¼(Scalar)ëŠ” ë‹¨ í•˜ë‚˜ì˜ ìˆ«ì(ì •ìˆ˜, ì‹¤ìˆ˜ ë“±)ë§Œì„ ë‹´ëŠ” ìë£Œí˜•ì„ ë§í•œë‹¤. íŒŒì´í† ì¹˜ì—ì„œ ìŠ¤ì¹¼ë¼ëŠ” 0ì°¨ì› í…ì„œ(0-dimensional Tensor, 0D)ë¡œ í‘œí˜„í•œë‹¤. ì¦‰, í…ì„œì˜ ì°¨ì›(Shape)ì´ ì „í˜€ ì—†ëŠ” ìƒíƒœë¥¼ ì˜ë¯¸í•œë‹¤.

**ìŠ¤ì¹¼ë¼(0D)**

```python
import torch

var = torch.tensor(5)
print(var) # tensor(5)
print(var.shape) # torch.Size([]) -> 0ì°¨ì› í…ì„œ
```

**ë²¡í„°(1D)**

```python
import torch

var = torch.tensor([10]) 
print(var.shape) # torch.Size([1]) -> 1ì°¨ì› í…ì„œ. ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹˜
```

**tensor -> int, float**

```python
import torch

var1 = torch.tensor(5)
var2 = torch.tensor(3)
result = var1 + var2
print(result)   # tensor(8)
print(result.item()) # 8 -> í…ì„œ ê°’(ìŠ¤ì¹¼ë¼)ì„ íŒŒì´ì¬ ìˆ«ìë¡œ ì¶”ì¶œ
```

### ë²¡í„° (Vector)4
ë²¡í„°ëŠ” í•˜ë‚˜ ì´ìƒì˜ ì›ì†Œê°€ ì¸ë ¬ë¡œ ë‚˜ì—´ëœ 1ì°¨ì› í…ì„œ(1D Tensor)ì„ ì˜ë¯¸í•œë‹¤. íŒŒì´í† ì¹˜(PyTorch)ì—ì„œ ë²¡í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ torch.tensor([...]) í˜•íƒœë¡œ ë§Œë“¤ë©°, ì´ë•Œ í…ì„œì˜ shape(ì°¨ì›)ê°€ (n,) í˜•íƒœì´ë‹¤. ì¦‰, ì›ì†Œê°€ nê°œ ë“¤ì–´ìˆìœ¼ë©´ 1ì°¨ì› ë²¡í„°ê°€ ëœë‹¤.

```python
import torch

var1 = torch.tensor([1.0, 2.0, 3.0])
print(var1) # tensor([1., 2., 3.])
print(var1.shape) # torch.Size([3]) -> 1ì°¨ì› í…ì„œ

var2 = var1 + 10
print(var2) # tensor([11., 12., 13.])
var3 = var1 * 2
print(var3) # tensor([2., 4., 6.])

var4 = torch.tensor([4.0, 5.0, 6.0])
result = var1 + var4
print(result) # tensor([5., 7., 9.])
```

### í–‰ë ¬ (Matrix)

í–‰ë ¬ì€ 2ì°¨ì› í˜•íƒœì˜ í…ì„œë¡œ, íŒŒì´í† ì¹˜(PyTorch)ì—ì„œëŠ” `shape`ê°€ `(m, n)`ì²˜ëŸ¼ 2ê°œì˜ ì°¨ì›ì„ ê°€ì§„ í…ì„œë¥¼ ì˜ë¯¸í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, torch.tensor([[1, 2], [3, 4]])ëŠ” 2í–‰ x 2ì—´ í˜•íƒœì˜ í–‰ë ¬ì´ë‹¤. í–‰ë ¬ ì—°ì‚°ì—ì„œëŠ” í–‰ë ¬ ê³±ì…ˆ, ì›ì†Œë³„ ì—°ì‚°, ì „ì¹˜(Transpose) ë“±ì´ ìì£¼ í™œìš©ë˜ë©°, íŒŒì´í† ì¹˜ëŠ” `torch.mm` ë˜ëŠ” `@ ì—°ì‚°ì`ë¥¼ í†µí•´ í–‰ë ¬ ê³±ì…ˆì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

```python
var1 = torch.tensor([[1, 2], [3, 4]])
var2 = torch.tensor([[5, 6], [7, 8]])

print(var1) # tensor([[1, 2], [3, 4]])
print(var1.shape) # torch.Size([2, 2]) -> 2ì°¨ì› í…ì„œ

result1 = var1 + var2
print(result) # tensor([[6, 8], [10, 12]])
result2 = var1 * var2
print(result2) # tensor([[5, 12], [21, 32]])
result3 = torch.mm(var1, var2)
print(result3) # tensor([[19, 22], [43, 50]])
result4 = var1 @ var2
print(result4) # tensor([[19, 22], [43, 50]])
```

## ë‹¤ì°¨ì› í…ì„œ

íŒŒì´í† ì¹˜(PyTorch)ì—ì„œ ë‹¤ì°¨ì› í…ì„œë€, ì—¬ëŸ¬ ì¶•(ì°¨ì›)ì„ ê°€ì§€ëŠ” í…ì„œë¥¼ ì˜ë¯¸í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 0ì°¨ì› í…ì„œëŠ” "ìŠ¤ì¹¼ë¼(Scala)", 1ì°¨ì› í…ì„œëŠ” "ë²¡í„°(Vector)", 2ì°¨ì› í…ì„œëŠ” "í–‰ë ¬(Matrix)", ê·¸ ì´ìƒì˜ 3ì°¨ì›, 4ì°¨ì› í…ì„œ ë“±ì„ í†µí‹€ì–´ "ë‹¤ì°¨ì› í…ì„œ(Multi-dimensional Tensor)"ë¼ê³  ë¶€ë¥¸ë‹¤. ë‹¤ì°¨ì› í…ì„œëŠ” ì´ë¯¸ì§€, ìŒì„±, ë™ì˜ìƒ, ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¹„ë¡¯í•˜ì—¬ ì—¬ëŸ¬ ì¶•ì„ í•„ìš”ë¡œ í•˜ëŠ” ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ í‘œí˜„í•  ë•Œ ì“°ì¸ë‹¤.

![tensor](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2F9qUBb%2FbtsLwdzdXkJ%2FAAAAAAAAAAAAAAAAAAAAAPTZDOtbdPGz8dxjcod_u53eHJXxADKgy7z0aD1DNsoi%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1767193199%26allow_ip%3D%26allow_referer%3D%26signature%3DG6fww1pJ0C1yAxDezDV8MDwQ4HA%253D)

```python
var = torch.tensor([
    [[1, 2],
    [3, 4]],

    [[5, 6],
    [7, 8]],

    [[9, 10],
    [11, 12]]
])

print(var.shape) # torch.Size([3, 2, 2])
```

## í…ì„œ

PyTorchì˜ í…ì„œ(Tensor)ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì‚¬ìš©ë˜ëŠ” ê¸°ë³¸ ë°ì´í„° êµ¬ì¡°ì´ë‹¤. í…ì„œëŠ” ë‹¤ì°¨ì› ë°°ì—´ë¡œ, Numpyì˜ ë°°ì—´ê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, **GPUì—ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤**ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆë‹¤. PyTorchì˜ í…ì„œëŠ” ë°ì´í„°ì˜ í‘œí˜„ë¿ë§Œ ì•„ë‹ˆë¼, **ìë™ ë¯¸ë¶„(autograd)** ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•™ìŠµì„ ë„ì™€ì¤€ë‹¤.

```python
data = [
    [1, 2],
    [3, 4]
]

t = torch.tensor(data)
print(t)

"""
tensor([[1, 2],
        [3, 4]])
"""
```

```python

```

### ì†ì‹¤ í•¨ìˆ˜ (Loss Function)

ì†ì‹¤í•¨ìˆ˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’

ì ˆëŒ“ê°’ì„ ë¯¸ë¶„í•  ë•Œ ê°’ì´ ì‚¬ë¼ì§€ëŠ” ë“± ë¬¸ì œê°€ ìƒê¸°ê¸° ë•Œë¬¸ì— ì†ì‹¤í•¨ìˆ˜ë¡œ, MSE, RMSE ë“±ì´ ì“°ì¸ë‹¤.


| êµ¬ë¶„ | Batch (ë°°ì¹˜) | Stochastic (í™•ë¥ ì ) | Mini-Batch (ë¯¸ë‹ˆë°°ì¹˜) |
|:-----:|------------|---------------|------------------|
| **ë°ì´í„° ì‚¬ìš© ë‹¨ìœ„** | ì „ì²´ ë°ì´í„°ì…‹ | í•˜ë‚˜ì˜ ë°ì´í„° í¬ì¸íŠ¸ | ì‘ì€ ë°ì´í„° ë¬¶ìŒ |
| **ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸ íšŸìˆ˜** | 1íšŒ / ì—í¬í¬ | 


### í•™ìŠµë¥  (Learning Rate)

í•™ìŠµë¥ ì€ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµí•  ë•Œ ê°€ì¤‘ì¹˜(Weights)ì™€ í¸í–¥(Biases)ë¥¼ ì–¼ë§ˆë‚˜ í¬ê²Œ ì¡°ì •í• ì§€ë¥¼ ê²°ì •í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°(ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì§€ ëª»í•˜ê³ , **ì‚¬ëŒ(ê°œë°œì)ì´ í•™ìŠµ ì‹œì‘ ì „ì— ì§ì ‘ ì •í•´ì£¼ì–´ì•¼ í•˜ëŠ” "ì„¤ì •ê°’"**)ì´ë‹¤. ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ê³¼ ê°™ì€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì†ì‹¤ í•¨ìˆ˜(Loss Function)ì˜ ê¸°ìš¸ê¸°(Gradient)ë¥¼ ë”°ë¼ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì•„ê°ˆ ë•Œ, í•™ìŠµë¥ ì€ í•œ ë²ˆì˜ ì—…ë°ì´íŠ¸ì—ì„œ ì´ë™í•˜ëŠ” "ê±¸ìŒì˜ í¬ê¸°"ë¥¼ ì˜ë¯¸í•œë‹¤.

í•™ìŠµë¥ ì´ ë„ˆë¬´ í¬ë©´ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì§€ë‚˜ì³ ë²„ë¦¬ê±°ë‚˜ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµì†ë„ê°€ ë§¤ìš° ëŠë ¤ì ¸ ìµœì  ê°’ì— ë„ë‹¬í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì ì ˆí•œ í•™ìŠµë¥ ì„ ì„ íƒí•˜ëŠ” ê²ƒì€ ëª¨ë¸ì˜ í•™ìŠµ ì†ë„ì™€ ìµœì í™” ì„±ëŠ¥ì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ê³ ì •ëœ í•™ìŠµë¥ ì„ ì‚¬ìš©í•˜ê¸°ë„ í•˜ì§€ë§Œ, ìƒí™©ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¤„ì´ê±°ë‚˜ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ë°©ë²• (ì˜ˆ: Adam, Step Decay, Cyclical Learning Rate ë“±)ì´ ì‚¬ìš©ë˜ê¸°ë„ í•œë‹¤.


### ì—í¬í¬(Epoch)ë€? 

ë”¥ëŸ¬ë‹ì—ì„œ ì „ì²´ í›ˆë ¨ ë°ì´í„°ì…‹ì´ ëª¨ë¸ì„ í•œ ë²ˆ í†µê³¼í•œ ìƒíƒœë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì‰½ê²Œ ë§í•´, ì¤€ë¹„í•œ ë¬¸ì œì§‘(í•™ìŠµ ë°ì´í„°)ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ ë”± í•œ ë²ˆ ë‹¤ í’€ì—ˆì„ ë•Œë¥¼ "1 ì—í¬í¬ê°€ ì§€ë‚¬ë‹¤"ë¼ê³  í•©ë‹ˆë‹¤.

![learning-rate](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fbo7nTS%2FbtsLz8ezGG6%2FAAAAAAAAAAAAAAAAAAAAAKvthCVYixeejQQDXy10UR6_GVQjs-i0sUyaUwsBHHrB%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1767193199%26allow_ip%3D%26allow_referer%3D%26signature%3DfbJGGG4N2Eg8DR%252Ffb%252FZmS1nvUEM%253D)

## ë…¼ë¦¬ íšŒê·€

### â€» ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ (Sigmoid Function)

ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ëŠ” ì…ë ¥ ê°’ì„ ë°›ì•„ì„œ ì´ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìˆ˜í•™ í•¨ìˆ˜ì´ë‹¤. ì£¼ë¡œ í™•ë¥ ì„ ì˜ˆì¸¡í•´ì•¼ í•˜ëŠ” ë¬¸ì œì—ì„œ ì‚¬ìš©ëœë‹¤.


ğŸ”„ ì „ì²´ íë¦„ ìš”ì•½zero_grad(): ê°€ì¤‘ì¹˜ë“¤ì˜ grad ì£¼ë¨¸ë‹ˆë¥¼ 0ìœ¼ë¡œ ë¹„ì›€.
Forward: ì—°ì‚° ì§€ë„ë¥¼ ê·¸ë¦¼ (ê¸°ìš¸ê¸° ê³„ì‚° ì¤€ë¹„).
backward(): ì§€ë„ë¥¼ ê±°ê¾¸ë¡œ íƒ€ë©° ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•´ì„œ grad ì£¼ë¨¸ë‹ˆì— ìƒˆë¡œ ì €ì¥.
step(): ì£¼ë¨¸ë‹ˆì— ì €ì¥ëœ ê°’ì„ ë³´ê³  ì‹¤ì œ ê°€ì¤‘ì¹˜($W$)ë¥¼ ìˆ˜ì •.
ê²°ë¡ : ê¸°ìš¸ê¸°ê°€ ì €ì¥ë˜ëŠ” ê³³ì€ ê°€ì¤‘ì¹˜ í…ì„œ ë‚´ë¶€ì˜ .grad ë³€ìˆ˜ì´ë©°, ì´ ê°’ì€ ìˆœì „íŒŒ ë•Œê°€ ì•„ë‹ˆë¼ backward()ê°€ ì‹¤í–‰ë˜ëŠ” ìˆœê°„ì— ê³„ì‚°ë˜ì–´ ì±„ì›Œì§‘ë‹ˆë‹¤!

### BCE ì†ì‹¤ í•¨ìˆ˜ (Binary Cross Entropy)
(MSE) ë‘˜ë‹¤ ì™¸ì›Œì£¼ê¸°!

Binary Cross Entropy (BCE)ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸” ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” **ì†ì‹¤ í•¨ìˆ˜ (Loss Function)**ì´ë‹¤.

#### ì‹¤ì œ ê°’ì´ 1ì¼ ë•Œ,

* 

#### ì‹¤ì œ ê°’ì´ 0ì¼ ë•Œ,

## ë‹¤í•­ ë…¼ë¦¬ íšŒê·€
ë‹¤í•­ ë…¼ë¦¬ íšŒê·€(Multinomial Logistic Regression)ëŠ” ì¢…ì† ë³€ìˆ˜ê°€ 

### Softmax Function

Softmax í•¨ìˆ˜ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜(Multiclass Classification) ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜(Activation Function)ì´ë‹¤. ì´ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì…ë ¥ ë²¡í„°ì˜ ê° ìš”ì†Œë¥¼ í™•ë¥  ë¶„í¬

### â€» axes.flatten()

## ë°ì´í„° ë¡œë” (Data Loader)

ë°ì´í„°ë¡œë”ëŠ” ë°ì´í„°ì…‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ë°ì´í„°ë¥¼ ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬ì´ë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„°ì…‹ì„ **ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì— ì œê³µ**í•˜ë©°, ë°ì´í„°ì˜ í¬ê¸°ê°€ í´ ê²½ìš°ì—ë„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. **ë°ì´í„° ì¦ê°•, ì…”í”Œë§, ë³‘ë ¬ì²˜ë¦¬ì™€ ê°™ì€ ê¸°ëŠ¥**ì„ ì§€ì›í•˜ë©° í•™ìŠµ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ , ëª¨ë¸ í•™ìŠµê³¼ í‰ê°€ ì‹œ ì¼ê´€ëœ ë°ì´í„° ì œê³µ ë°©ì‹ì„ ìœ ì§€í•œë‹¤. ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì—ì„œëŠ” PyTorchì˜ DataLoaderë‚˜ TensorFlowì˜ tf.data ê°™ì€ ë„êµ¬ë¥¼ í†µí•´ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

### â€» ë°ì´í„°ë¡œë”ì˜ ì£¼ìš” ì—­í• 

> - ë°°ì¹˜ ì²˜ë¦¬: ë°ì´í„°ë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì— ì œê³µ
> 

## ë°ì´í„° ì¦ê°• (Data Augmentation)

