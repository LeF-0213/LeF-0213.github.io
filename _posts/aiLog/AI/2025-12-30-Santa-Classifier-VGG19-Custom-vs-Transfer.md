---
layout: post
related_posts:
  - /aiLog/ai
title:  "Santa vs ì¼ë°˜ì¸ ì´ë¯¸ì§€ ë¶„ë¥˜ (VGG19 ì§ì ‘ êµ¬í˜„ & ì „ì´í•™ìŠµ)"
date:   2025-12-24
categories:
  - ai
description: >
  VGG19 ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ê³ , ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì „ì´ í•™ìŠµê³¼ ì„±ëŠ¥ ë¹„êµ
---
* toc
{:toc .large-only}

## VGG-19 Architecture

VGG-19ëŠ” **16ê°œì˜ í•©ì„±ê³µ ê³„ì¸µ(Convolutional layer)** ê³¼ **3ê°œì˜ ì™„ì „ ì—°ê²° ì¸µ(Fully Connected layer)** ìœ¼ë¡œ êµ¬ì„±ëœ **ì´ 19ê°œ** ì˜ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ë¥¼ ê°€ì§„ ì‹¬ì¸µ ì»¨ë¸”ë£¨ì…˜ ì‹ ê²½ë§(DCNN)ì´ë‹¤.

### í•µì‹¬ êµ¬ì„± ìš”ì†Œ
- **Convolution Layers**:
    - 3x3 í¬ê¸°ì˜ ì‘ì€ í•„í„°ë¥¼ ì‚¬ìš©í•˜ë©°,
    - stride 1ê³¼ padding 1 ì„¤ì •ì„ í†µí•´ ì—°ì‚° í›„ì—ë„ ì´ë¯¸ì§€ì˜ ê°€ë¡œÂ·ì„¸ë¡œ í¬ê¸°(ê³µê°„ í•´ìƒë„)ê°€ ì¤„ì–´ë“¤ì§€ ì•Šê³  ìœ ì§€ë˜ë„ë¡ ì„¤ê³„
- **Activation Function (í™œì„±í™” í•¨ìˆ˜: ReLU)**:
    - ëª¨ë“  í•©ì„±ê³±ì¸µê³¼ ì—°ê²°ì¸µ ë‹¤ìŒì— **ReLU(Rectified Linear Unit)** í•¨ìˆ˜ ì ìš©
- **Pooling Layers (Max Pooling)**:
    - 2x2 í•„í„°ì™€ stride 2ë¥¼ ì‚¬ìš©í•˜ëŠ” Max Pooling ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê³µê°„ ì°¨ì›ì„ ì¶•ì†Œ 
- **Fully Connected Layers (ì™„ì „ ì—°ê²° ì¸µ: FC Layers)**:
    - ë¶„ë¥˜ë¥¼ ìœ„í•´ ë„¤íŠ¸ì›Œí¬ ë§ˆì§€ë§‰ ë¶€ë¶„ì— ìœ„ì¹˜í•œ 3ê°œì˜ ì¸µìœ¼ë¡œ,
    - ì•ì„  ê³¼ì •ì—ì„œ ì¶”ì¶œëœ 2ì°¨ì› íŠ¹ì§• ë§µë“¤ì„ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹œ(Flatten) í›„ ì—°ê²°í•œë‹¤.
- **Softmax Layer**:
    - ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¥ ë§ˆì§€ë§‰ì— ìœ„ì¹˜í•˜ëŠ” ì¶œë ¥ ì¸µìœ¼ë¡œ ì™„ì „ ì—°ê²° ì¸µì—ì„œ ë‚˜ì˜¨ ìˆ˜ì¹˜ë“¤ì„ 0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥  ê°’ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
    - í™•ë¥  ê°’ì˜ í•©ì€ 1ì´ë©°, ì´ë¥¼ í†µí•´ íŠ¹ì • í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•  ìµœì¢… í™•ë¥ ì„ ì¶œë ¥í•œë‹¤.

### VGG-19ì˜ ì„¤ê³„ ì›ì¹™
- **Uniform Convolution Filters (ê· ì¼í•œ í•©ì„±ê³± í•„í„°)** :
    - ëª¨ë¸ ì „ì²´ì—ì„œ ì˜¤ì§ **3x3 í¬ê¸°ì˜ í•„í„°ë§Œ ì‚¬ìš©**
    - í•„í„°ë¥¼ ë‘ ê°œ ìŒ“ìœ¼ë©´ 5x5 í•„í„° í•œ ê°œì™€ ê°™ê³ , ì„¸ ê°œ ìŒ“ìœ¼ë©´ 7x7ê³¼ ê°™ì•„ì§„ë‹¤.
    - ë•Œë¬¸ì— í•„í„° í¬ê¸°ë¥¼ ì‘ê²Œ ê³ ì •í•˜ë©´ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì¤„ì´ë©´ì„œ ì¸µì„ ë” ê¹Šê²Œ ìŒ“ì„ ìˆ˜ ìˆì–´ ëª¨ë¸ì˜ í•™ìŠµ ëŠ¥ë ¥ì´ ê·¹ëŒ€í™” ëœë‹¤. 
- **Deep Architectrue (ê¹Šì€ ì•„í‚¤í…ì²˜)** :
    - ì¸µì˜ ê°œìˆ˜ë¥¼ 19ê°œê¹Œì§€ ëŠ˜ë ¤ ë„¤íŠ¸ì›Œí¬ ê¹Šì´ë¥¼ ê¹Šê²Œ ê°€ì ¸ê°„ë‹¤.
    - ë„¤íŠ¸ì›Œí¬ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ AIëŠ” ë‹¨ìˆœí•œ ì„ ì´ë‚˜ ìƒ‰ìƒ ë‹¨ê³„ë¥¼ ë„˜ì–´, ì‚¬ë¬¼ì˜ ë³µì¡í•œ í˜•íƒœë‚˜ ì¶”ìƒì ì¸ ê°œë…(ì˜ˆ: ë™ë¬¼ì˜ ê·€, ìë™ì°¨ íœ  ë“±)ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì •êµí•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ëœë‹¤. 
- **ReLU Activation (ReLU í™œì„±í™” í•¨ìˆ˜)** :
    - ëª¨ë“  ì—°ì‚° ì¸µ ë’¤ì— ë¹„ì„ í˜• í•¨ìˆ˜ì¸ ReLUë¥¼ ë°°ì¹˜í•œë‹¤.
    - í™œì„±í™” í•¨ìˆ˜ëŠ” ì‹ ê²½ë§ì— 'ë¹„ì„±í˜•ì„±'ì„ ë¶€ì—¬í•˜ì—¬, ëª¨ë¸ì€ ë‹¨ìˆœí•œ ì„ í˜• ê²°í•©ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ì—†ëŠ” ë³µì¡í•˜ê³  ê¼¬ì—¬ ìˆëŠ” ë°ì´í„° íŒ¨í„´ì„ ìœ ì—°í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. 
- **Max Pooling** :
    - ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¸°ê³  ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ë‚˜ê°€ëŠ” ê²ƒ.
    - ì´ëŠ” ê³„ì‚° ì†ë„ë¥¼ ë†’ì¼ ë¿ë§Œ ì•„ë‹ˆë¼, ë¬¼ì²´ê°€ ì´ë¯¸ì§€ ë‚´ì—ì„œ ì¡°ê¸ˆ ì´ë™í•˜ê±°ë‚˜ ì™œê³¡ë˜ì–´ë„ ë™ì¼í•˜ê²Œ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ 'ê³µê°„ì  ë¶ˆë³€ì„±'ì„ ì œê³µí•œë‹¤.
- **Fully Connected Layers** :
    - ì¶”ì¶œëœ ëª¨ë“  íŠ¹ì§•ì„ í•˜ë‚˜ë¡œ ëª¨ì•„ ë¶„ë¥˜í•œë‹¤.
    - ì•ì„  ì¸µë“¤ì´ ì´ë¯¸ì§€ì˜ 'íŠ¹ì§•'ì„ ì°¾ëŠ” ì—­í• ì´ì—ˆë‹¤ë©´, FC LayersëŠ” ì°¾ì•„ë‚¸ ëª¨ë“  ì¡°ê° ì •ë³´(ì˜ˆ: í„¸, ê¼¬ë¦¬, ëˆˆ ëª¨ì–‘)ë¥¼ ì¢…í•©í•˜ì—¬ "ì´ ì‚¬ì§„ì€ ê³ ì–‘ì´ì…ë‹ˆë‹¤." ë¼ê³  ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦¬ëŠ” íŒë‹¨ ì¥ì¹˜ ì—­í• ì„ í•œë‹¤. 

### íŠ¹ì§•
- **Model Simplicity and Effectiveness (ëª¨ë¸ì˜ ë‹¨ìˆœì„±ê³¼ íš¨ê³¼ì„±)**:
    - VGG-19ì˜ êµ¬ì¡°ê°€ ë§¤ìš° ì§ê´€ì ì´ë‹¤. ëª¨ë“  ë¸”ë¡ì—£ ì¼ê´€ë˜ê²Œ **3x3 í•„í„°** ë¥¼ ì‚¬ìš©í•˜ê³ , ë™ì¼í•œ íŒ¨í„´ì˜ ë¸”ë¡ì„ ë°˜ë³µì ìœ¼ë¡œ ìŒ“ì•„ì˜¬ë ¸ë‹¤.
    - ì•„í‚¤í…ì²˜ê°€ ë³µì¡í•˜ì§€ ì•Šì•„ ì„¤ê³„ì™€ êµ¬í˜„ì´ ë§¤ìš° ì‰½ê³ , ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ì‘ì—…(ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ íƒì§€ ë“±)ì—ì„œ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì•ˆì •ì ì´ë‹¤.
- **Computational Requirements (ì»´í“¨íŒ… ìì› ìš”êµ¬ ì‚¬í•­)**:
    - VGG-19ì˜ ê°€ì¥ í° ë‹¨ì ì€ **ë§¤ìš° ë¬´ê²ë‹¤** ëŠ” ê²ƒì´ë‹¤.
    - 19ê°œì˜ ê¹Šì€ ì¸µê³¼ ìˆ˜ë§ì€ í•„í„° ë•Œë¬¸ì— í•™ìŠµí•´ì•¼ í•  íŒŒë¼ë¯¸í„°ê°€ ì•½ 1ì–µ 4ì²œë§Œê°œì— í•´ë‹¹í•œë‹¤.
- **Robust Feature Extraction (ê°•ë ¥í•œ íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥)**:
    - ì¸µì´ ë§¤ìš° ê¹Šê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ ì†ì˜ ì•„ì£¼ ë¯¸ì„¸í•˜ê³  ë³µì¡í•œ íŠ¹ì§•(í…ìŠ¤ì²˜, ì‚¬ë¬¼ì˜ ë¶€ìœ„ ë“±)ì„ ì¡ì•„ë‚´ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•˜ë‹¤.
    -  **(ì „ì´ í•™ìŠµ, Transfer Learning) í™œìš©**:
        - ì´ë¯¸ ê±°ëŒ€ ë°ì´í„°(ImageNet)ë¡œ í•™ìŠµëœ VGG-19ì˜ **'ê°€ì¤‘ì¹˜(Weights)'** ë¥¼ ê°€ì§€ì—¬ì™€ì„œ, ë‚´ê°€ ê°€ì§„ ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ ê³ ì„±ëŠ¥ AIë¥¼ ë§Œë“œëŠ” **ì „ì´ í•™ìŠµ** ì˜ ê¸°ì´ˆ ëª¨ë¸ë¡œ ìì£¼ ì‚¬ìš©ëœë‹¤.
- **Data Augmentation (ë°ì´í„° ì¦ê°•)**:
    - ëª¨ë¸ì´ ë„ˆë¬´ ê¹Šìœ¼ë©´ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ê³¼í•˜ê²Œ ìµìˆ™í•´ì§€ëŠ” **'ê³¼ì í•©'** ì´ ë°œìƒí•˜ê¸° ì‰½ë‹¤.
    - ì´ë¥¼ ë§‰ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ë³€í˜•í•˜ëŠ”ë° ë‹¤ì–‘í•œ ë°ì´í„° ì¦ê°• ê¸°ë²•ì´ ì‚¬ìš©ëœë‹¤.
        -  **Random Cropping**: ì‚¬ì§„ì„ ë¬´ì‘ìœ„ë¡œ ìë¥´ëŠ” ê¸°ë²•
        -  **Horizontal Flipping**: ì¢Œìš°ë¥¼ ë°˜ì „ì‹œí‚¤ëŠ” ê¸°ë²•
        -  **Color Jittering**: ìƒ‰ìƒì„ ì‚´ì§ ë°”ê¾¸ëŠ” ê¸°ë²•
- **Influence on Network Design (ë„¤íŠ¸ì›Œí¬ ì„¤ê³„ì— ë¯¸ì¹œ ì˜í–¥)**:
    - 'í° í•„í„° í•˜ë‚˜ë³´ë‹¤ ì‘ì€ í•„í„° ì—¬ëŸ¬ê°œê°€ ë‚«ë‹¤'
    - 'ë§ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ë‹¤'
    - ì´ ë‘ ì›ì¹™ì€ ì´í›„ ë“±ì‘í•œ ResNet(ì”ì°¨ í•™ìŠµ)ì´ë‚˜ Inception(ë³‘ë ¬ êµ¬ì¡°)ê°™ì€ í˜„ëŒ€ì  AI ëª¨ë¸ë“¤ì´ íƒ„ìƒí•˜ëŠ” ë°‘ê±°ë¦„ì´ ë˜ì—ˆìœ¼ë©°, í˜„ì¬ê¹Œì§€ë„ ì»´í“¨í„° ë¹„ì „ ì—°êµ¬ì˜ ì¤‘ìš”í•œ ê¸°ì¤€ì ìœ¼ë¡œ í™œìš©ë˜ê³  ìˆë‹¤. 

<img src='https://media.geeksforgeeks.org/wp-content/uploads/20240607123924/VGG--19-Architecture-.webp' width=650px/>


```python
!pip install torchvision
```

    Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.24.1)
    Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (2.2.6)
    Requirement already satisfied: torch==2.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (2.9.1)
    Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (12.0.0)
    Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.20.1)
    Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (4.15.0)
    Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (80.9.0)
    Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.14.0)
    Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.6.1)
    Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.1.6)
    Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2025.12.0)
    Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)
    Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.3)



```python
import torch
# nn: Neutral Network, ì¸ê³µì‹ ê²½ë§ ì¸µ(Layer)ì„ ìŒ“ì„ ë•Œ ì‚¬ìš©
import torch.nn as nn
# optimizer: ìµœì í™” ì•Œê³ ë¦¬ì¦˜
import torch.optim as optim
# ëª¨ë¸ì—ê²Œ batch ì‚¬ì´ì¦ˆë§Œí¼ì˜ ë°ì´í„°ë¥¼ ì „ë‹¬
from torch.utils.data import DataLoader
# models: ì´ë¯¸ ë§Œë“¤ì–´ì§„ ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë„êµ¬
# transforms: Resize, ToTensor, Normalize ë“± ë°ì´í„°ë¥¼ ë³€í˜•í•˜ê¸° ìœ„í•œ ë„êµ¬
from torchvision import datasets, transforms, models
import matplotlib.pyplot as plt
import numpy as np
import time
import os
os.environ['MallocStackLogging'] = '0'
```


```python
# GPU í™•ì¸
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(device)
```

    mps


## VGG ì§ì ‘ êµ¬í˜„
Block 1
- Conv1_1: 64 filters, 3x3 kernel, ReLU activation
- Conv1_2: 64 filters, 3x3 kernel, ReLU activation
- Max Pooling: 2x2 filter, stride 2
  
Block 2
- Conv2_1: 128 filters, 3x3 kernel, ReLU activation
- Conv2_2: 128 filters, 3x3 kernel, ReLU activation
- Max Pooling: 2x2 filter, stride 2
  
Block 3
- Conv3_1: 256 filters, 3x3 kernel, ReLU activation
- Conv3_2: 256 filters, 3x3 kernel, ReLU activation
- Conv3_3: 256 filters, 3x3 kernel, ReLU activation
- Conv3_4: 256 filters, 3x3 kernel, ReLU activation
- Max Pooling: 2x2 filter, stride 2
  
Block 4
- Conv4_1: 512 filters, 3x3 kernel, ReLU activation
- Conv4_2: 512 filters, 3x3 kernel, ReLU activation
- Conv4_3: 512 filters, 3x3 kernel, ReLU activation
- Conv4_4: 512 filters, 3x3 kernel, ReLU activation
- Max Pooling: 2x2 filter, stride 2
  
Block 5
- Conv5_1: 512 filters, 3x3 kernel, ReLU activation
- Conv5_2: 512 filters, 3x3 kernel, ReLU activation
- Conv5_3: 512 filters, 3x3 kernel, ReLU activation
- Conv5_4: 512 filters, 3x3 kernel, ReLU activation
- Max Pooling: 2x2 filter, stride 2
  
Fully Connected Layers
- FC1: 4096 neurons, ReLU activation
- FC2: 4096 neurons, ReLU activation
- FC3: 1000 neurons, softmax activation (for 1000-class classification)


```python
class VGG19FromScratch(nn.Module):
    # num_classesëŠ” AIê°€ ìµœì¢…ì ìœ¼ë¡œ ë¶„ë¥˜í•  ì •ë‹µì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸
    # ì‚°íƒ€ì¸ì§€ ì•„ë‹Œì§€ ì´ì§„ ë¶„ë¥˜ì´ë¯€ë¡œ num_classes=2
    def __init__(self, num_classes=2):
        super().__init__()
        
        # Block 1
        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Block 2
        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Block 3
        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Block 4
        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Block 5
        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)
        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)

        #ReLU
        self.relu = nn.ReLU(inplace=True)

        # FC Layers
        self.fc1 = nn.Linear(512 * 7 * 7, 4096)
        self.fc2 = nn.Linear(4096, 4096)
        self.fc3 = nn.Linear(4096, num_classes)
        self.dropout = nn.Dropout(0.5)

        self._initialize_weights()

    def forward(self, x):
        # Block 1
        x = self.relu(self.conv1_1(x))
        x = self.relu(self.conv1_2(x))
        x = self.pool1(x)
        
        # Block 2
        x = self.relu(self.conv2_1(x))
        x = self.relu(self.conv2_2(x))
        x = self.pool2(x)

        # Block 3
        x = self.relu(self.conv3_1(x))
        x = self.relu(self.conv3_2(x))
        x = self.relu(self.conv3_3(x))
        x = self.relu(self.conv3_4(x))
        x = self.pool3(x)

        # Block 4
        x = self.relu(self.conv4_1(x))
        x = self.relu(self.conv4_2(x))
        x = self.relu(self.conv4_3(x))
        x = self.relu(self.conv4_4(x))
        x = self.pool4(x)

        # Block 5
        x = self.relu(self.conv5_1(x))
        x = self.relu(self.conv5_2(x))
        x = self.relu(self.conv5_3(x))
        x = self.relu(self.conv5_4(x))
        x = self.pool5(x)

        # Flatten
        # x.shape(): [batch size, channel, height, width]
        x = x.flatten(start_dim=1)

        # FC
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)

        return x

    # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ë¥¼ í•˜ê¸° ìœ„í•¨
    def _initialize_weights(self):
        # ëª¨ë¸ ì•ˆì— ë“¤ì–´ìˆëŠ” ëª¨ë“  ì¸µ(Conv, ReLU, Linear ë“±)ì„ í•˜ë‚˜í•˜ë‚˜ êº¼ë‚´ì£¼ëŠ” ì—­í• 
        for m in self.modules():
            # êº¼ë‚¸ mì´ Conv2d ì¸µì¸ì§€ í™•ì¸
            if isinstance(m, nn.Conv2d):
                # nn.init.kaimin_normal_(): He ì´ˆê¸°í™”, 
                # ì¸µì´ ê¹Šì–´ì§€ë©´ ìˆ«ìë“¤ì´ ë„ˆë¬´ ì‘ì•„ì§€ê±°ë‚˜ ì»¤ì ¸ì„œ í•™ìŠµì´ ì•ˆ ë˜ëŠ” ë¬¸ì œ(ê¸°ìš¸ê¸° ì†Œì‹¤/ í­ë°œ)ê°€ ìƒê¸´ë‹¤.
                # ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìˆ˜í•™ì ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ë²”ìœ„ì˜ ë‚œìˆ˜ë¥¼ ì±„ì›Œì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
                # mode=''fan_out': ì…ë ¥ ë°ì´í„°ê°€ ì•„ë‹ˆë¼ ì¶œë ¥ ì±„ë„ì˜ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ê² ë‹¤ë¼ëŠ” ì˜ë¯¸
                # nonlinearity=relu': ReLUë¥¼ ì“¸ í…Œë‹ˆ ê±°ê¸°ì— ë§ì¶° ê³„ì‚°í•´ë‹¬ë¼ëŠ” ìš”ì²­
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                # ê°€ì¤‘ì¹˜ë¥¼ 'í‰ê·  0, í‘œì¤€í¸ì°¨ 0.01ì¸ ì •ê·œë¶„í¬'ì—ì„œ ë¬´ì‘ìœ„ë¡œ ë½‘ì•„ ì±„ìš´ë‹¤.
                # ì•„ì£¼ ì‘ì€ ê°’ë“¤ë¡œ ì±„ì›Œì„œ, ëª¨ë¸ì´ ì²˜ìŒë¶€í„° ë„ˆë¬´ ê°•í•œ í¸ê²¬ì„ ê°–ì§€ ì•Šê³  í•™ìŠµì„ ì‹œì‘í•˜ê²Œ ëœë‹¤.
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```

## ì „ì´í•™ìŠµ VGG19
[VGG19_Weights.IMAGENET1K_V1](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vgg19.html#torchvision.models.VGG19_Weights)

The inference transforms are available at VGG19_Weights.IMAGENET1K_V1.transforms and perform the following preprocessing operations: Accepts PIL.Image, batched (B, C, H, W) and single (C, H, W) image torch.Tensor objects. The images are resized to resize_size=[256] using interpolation=InterpolationMode.BILINEAR, followed by a central crop of crop_size=[224]. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].


```python
from torchvision.models import VGG19_Weights
```


```python
model = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1)
print(model)
```

    VGG(
      (features): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace=True)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace=True)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace=True)
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (17): ReLU(inplace=True)
        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace=True)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace=True)
        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (24): ReLU(inplace=True)
        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (26): ReLU(inplace=True)
        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace=True)
        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (31): ReLU(inplace=True)
        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (33): ReLU(inplace=True)
        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (35): ReLU(inplace=True)
        (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
      (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=4096, bias=True)
        (4): ReLU(inplace=True)
        (5): Dropout(p=0.5, inplace=False)
        (6): Linear(in_features=4096, out_features=1000, bias=True)
      )
    )



```python
def VGG19Transfer(num_classes=2, freeze_features=True):
    model = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1)

    if freeze_features:
        for param in model.features.parameters():
            # requires_grad = True: ê³„ì‚° ê²°ê³¼ë¥¼ ëˆ„ì ì‹œí‚´ (ë‚˜ì¤‘ì— ë¯¸ë¶„ì„ í•˜ê¸° ìœ„í•´ì„œ)
            # requires_grad = False: ë” ì´ìƒ ê¸°ìš¸ê¸°ë¥¼ ì—…ë°ì´íŠ¸ í•˜ì§€ ì•Šê² ë‹¤. ê¸°ìš¸ê¸° ê³ ì •
            param.requires_grad = False

    model.classifier = nn.Sequential(
        nn.Linear(512 * 7 * 7, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(0.5),
        nn.Linear(4096, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(0.5),
        nn.Linear(4096, num_classes) # ë§ˆì§€ë§‰ë§Œ ì´ì§„ ë¶„ë¥˜ë¡œ ìˆ˜ì •
    )

    return model
```

## ë°ì´í„° ë¡œë”©


```python
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 244)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 244)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((224, 244)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}
```


```python
data_dir = {
    'train': './data/santa/train',
    'val': './data/santa/val',
    'test': './data/santa/test'
}
```


```python
image_datasets = {
    # ImageFolder(): í´ë” ì•ˆì— ìˆëŠ” ê²½ë¡œë¥¼ ë ˆì´ë¸”ë¡œ ì‚¼ê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒ, í´ë” ìˆœìœ¼ë¡œ ë ˆì´ë¸” 0, 1 ... ì§€ì •
    # ImageFolderëŠ” í´ë” êµ¬ì¡°ë¥¼ ë³´ê³  ìë™ìœ¼ë¡œ ì •ë‹µ(Label)ì„ ë‹¬ì•„ì£¼ëŠ” ë„êµ¬
    x: datasets.ImageFolder(data_dir[x], transform=data_transforms[x])
    for x in ['train', 'val', 'test']
}
```


```python
dataloaders = {
    x: DataLoader(image_datasets[x],
                  batch_size=32,
                  shuffle=(x=='train'),
                  num_workers=2)
    for x in ['train', 'val', 'test']
}
```


```python
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}
class_names = image_datasets['train'].classes
print(f"dataset_sizes: {dataset_sizes}")
print(f"classe_names: {class_names}")
```

    dataset_sizes: {'train': 895, 'val': 267, 'test': 68}
    classe_names: ['normal', 'santa']


## í•™ìŠµ í•¨ìˆ˜


```python
def train_model(model, criterion, optimizer, num_epochs=20, model_name="Model"):
    model = model.to(device)
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': [],
        'epoch_time': []
    }

    best_val_acc = 0.0

    print(f"\n{'='*70}")
    print(f"{model_name} í•™ìŠµì‹œì‘")
    print(f"{'='*70}\n")

    for epoch in range(num_epochs):
        start_time = time.time()
        
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_losses = 0.0
            running_accs = 0
            
            for x_batch, y_batch in dataloaders[phase]:
                x_batch, y_batch = x_batch.to(device), y_batch.to(device)

                if phase == 'train':
                    y_pred = model(x_batch)
                    _, preds = torch.max(y_pred, 1)
                    loss = criterion(y_pred, y_batch)

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                else:
                    with torch.no_grad():
                        y_pred = model(x_batch)
                        _, preds = torch.max(y_pred, 1)
                        loss = criterion(y_pred, y_batch)

                running_losses += loss.item() * x_batch.size(0)
                running_accs += torch.sum(preds == y_batch.data)

            epoch_loss = running_losses / dataset_sizes[phase]
            epoch_acc = running_accs.float() / dataset_sizes[phase] * 100

            if phase == 'train':
                history['train_loss'].append(epoch_loss)
                history['train_acc'].append(epoch_acc.item())
            else:
                history['val_loss'].append(epoch_loss)
                history['val_acc'].append(epoch_acc.item())

                # Best model ì €ì¥
                if epoch_acc > best_val_acc:
                    best_val_acc = epoch_acc
                    torch.save(model.state_dict(), f'{model_name}_best.pth')

        epoch_time = time.time() - start_time
        history['epoch_time'].append(epoch_time)

        print(f'Epoch [{epoch+1} / {num_epochs}]')
        print(f'Train Loss: {history['train_loss'][-1]:.4f} Acc: {history["train_acc"][-1]:.2f}%')
        print(f'Val Loss: {history["val_loss"][-1]:.4f} Acc: {history["val_acc"][-1]:.2f}%')
        print(f'Time: {epoch_time:.2f}s')

    print(f'{model_name} í•™ìŠµ ì™„ë£Œ')
    print(f'Best Validaton Accuracy: {best_val_acc:.2f}%')

    return history
```

## í…ŒìŠ¤íŠ¸ í•¨ìˆ˜


```python
def test_model(model, criterion, model_name="Model"):
    model = model.to(device)
    model.eval()

    test_losses = 0.0
    test_accs = 0

    print(f"\n{'='*70}")
    print(f"{model_name} Test ì‹œì‘")
    print(f"{'='*70}")

    with torch.no_grad():
        for x_batch, y_batch in dataloaders['test']:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)

            y_pred = model(x_batch)
            _, preds = torch.max(y_pred, 1)
            loss = criterion(y_pred, y_batch)

            test_losses += loss.item() * x_batch.size(0)
            test_accs += torch.sum(preds == y_batch.data)

    test_loss = test_losses / dataset_sizes['test']
    test_acc = test_accs.float() / dataset_sizes['test'] * 100

    print(f'Test Loss: {test_loss:.4f}')
    print(f'Test Accuracy: {test_acc:.2f}% ({test_accs}/{dataset_sizes['test']})')

    return test_acc.item()
```

## í•™ìŠµ ì‹¤í–‰

### VGG19 ì§ì ‘ êµ¬í˜„ í•™ìŠµ


```python
model_scratch = VGG19FromScratch(num_classes=2)
# ì²˜ìŒë¶€í„° êµ¬í˜„í•  ëª¨ë¸ì´ë¼ í•™ìŠµë¥ ì„ ë‚®ì¶° ì•ˆì •ì ìœ¼ë¡œ ê¸°ì´ˆë¥¼ ìŒ“ì•„ê°€ê¸° ìœ„í•¨.
optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=0.0001)
history_scratch = train_model(model_scratch, nn.CrossEntropyLoss(), optimizer_scratch, model_name="VGG19_Scratch")
```

    
    ======================================================================
    VGG19_Scratch í•™ìŠµì‹œì‘
    ======================================================================
    
    Epoch [1 / 20]
    Train Loss: 0.7066 Acc: 57.88%
    Val Loss: 0.6757 Acc: 49.81%
    Time: 85.46s
    Epoch [2 / 20]
    Train Loss: 0.5773 Acc: 67.60%
    Val Loss: 0.3747 Acc: 86.89%
    Time: 85.77s
    Epoch [3 / 20]
    Train Loss: 0.3899 Acc: 84.80%
    Val Loss: 0.3380 Acc: 87.27%
    Time: 86.19s
    Epoch [4 / 20]
    Train Loss: 0.3730 Acc: 85.81%
    Val Loss: 0.4252 Acc: 89.14%
    Time: 99.07s
    Epoch [5 / 20]
    Train Loss: 0.3408 Acc: 87.04%
    Val Loss: 0.2797 Acc: 87.27%
    Time: 116.92s
    Epoch [6 / 20]
    Train Loss: 0.2785 Acc: 87.82%
    Val Loss: 0.2017 Acc: 92.13%
    Time: 105.82s
    Epoch [7 / 20]
    Train Loss: 0.2941 Acc: 89.83%
    Val Loss: 0.4500 Acc: 77.15%
    Time: 111.79s
    Epoch [8 / 20]
    Train Loss: 0.3338 Acc: 86.26%
    Val Loss: 0.2879 Acc: 90.26%
    Time: 110.20s
    Epoch [9 / 20]
    Train Loss: 0.2910 Acc: 88.60%
    Val Loss: 0.1887 Acc: 92.51%
    Time: 87.49s
    Epoch [10 / 20]
    Train Loss: 0.2436 Acc: 89.61%
    Val Loss: 0.1992 Acc: 93.63%
    Time: 112.10s
    Epoch [11 / 20]
    Train Loss: 0.2242 Acc: 90.50%
    Val Loss: 0.2136 Acc: 92.51%
    Time: 98.13s
    Epoch [12 / 20]
    Train Loss: 0.2370 Acc: 90.17%
    Val Loss: 0.2271 Acc: 92.51%
    Time: 99.57s
    Epoch [13 / 20]
    Train Loss: 0.2081 Acc: 91.40%
    Val Loss: 0.2109 Acc: 91.76%
    Time: 97.42s
    Epoch [14 / 20]
    Train Loss: 0.2175 Acc: 91.51%
    Val Loss: 0.3358 Acc: 92.13%
    Time: 105.20s
    Epoch [15 / 20]
    Train Loss: 0.2077 Acc: 92.18%
    Val Loss: 0.1706 Acc: 93.26%
    Time: 102.27s
    Epoch [16 / 20]
    Train Loss: 0.1704 Acc: 93.63%
    Val Loss: 0.2005 Acc: 93.63%
    Time: 110.04s
    Epoch [17 / 20]
    Train Loss: 0.1776 Acc: 92.51%
    Val Loss: 0.2180 Acc: 91.01%
    Time: 115.92s
    Epoch [18 / 20]
    Train Loss: 0.3082 Acc: 86.70%
    Val Loss: 0.3792 Acc: 86.89%
    Time: 1002.46s
    Epoch [19 / 20]
    Train Loss: 0.3178 Acc: 87.26%
    Val Loss: 0.2600 Acc: 91.39%
    Time: 1065.16s
    Epoch [20 / 20]
    Train Loss: 0.2650 Acc: 89.61%
    Val Loss: 0.2313 Acc: 90.26%
    Time: 91.19s
    VGG19_Scratch í•™ìŠµ ì™„ë£Œ
    Best Validaton Accuracy: 93.63%



```python
test_acc_scratch = test_model(model_scratch, nn.CrossEntropyLoss(), "VGG19_Scratch")
```

    
    ======================================================================
    VGG19_Scratch Test ì‹œì‘
    ======================================================================
    Test Loss: 0.2395
    Test Accuracy: 89.71% (61/68)



```python
### VGG19 ì „ì´í•™ìŠµ
```


```python
model_transfer = VGG19Transfer(num_classes=2, freeze_features=True)
# ì´ë¯¸ í•™ìŠµì´ ë˜ì–´ìˆê¸°ì— ì„±ëŠ¥ì„ ë¹ ë¥´ê²Œ ì˜¬ë¦¬ê¸° ìœ„í•´ í•™ìŠµë¥ ì„ ë†’ì„.
optimizer_transfer = optim.Adam(model_transfer.parameters(), lr=0.001)
history_transfer = train_model(model_transfer, nn.CrossEntropyLoss(), optimizer_transfer, model_name="VGG19_Transfer")
```

    
    ======================================================================
    VGG19_Transfer í•™ìŠµì‹œì‘
    ======================================================================
    
    Epoch [1 / 20]
    Train Loss: 2.6082 Acc: 86.93%
    Val Loss: 0.3802 Acc: 84.64%
    Time: 47.07s
    Epoch [2 / 20]
    Train Loss: 0.3135 Acc: 94.08%
    Val Loss: 0.2165 Acc: 94.38%
    Time: 49.13s
    Epoch [3 / 20]
    Train Loss: 0.2009 Acc: 95.08%
    Val Loss: 0.1871 Acc: 94.01%
    Time: 48.81s
    Epoch [4 / 20]
    Train Loss: 0.0873 Acc: 97.88%
    Val Loss: 0.1394 Acc: 95.51%
    Time: 52.60s
    Epoch [5 / 20]
    Train Loss: 0.1610 Acc: 97.09%
    Val Loss: 0.2756 Acc: 96.63%
    Time: 48.50s
    Epoch [6 / 20]
    Train Loss: 0.0884 Acc: 98.66%
    Val Loss: 0.1893 Acc: 96.25%
    Time: 47.05s
    Epoch [7 / 20]
    Train Loss: 0.0531 Acc: 98.44%
    Val Loss: 0.2144 Acc: 94.76%
    Time: 47.92s
    Epoch [8 / 20]
    Train Loss: 0.0669 Acc: 98.55%
    Val Loss: 0.5348 Acc: 95.51%
    Time: 65.11s
    Epoch [9 / 20]
    Train Loss: 0.2980 Acc: 96.76%
    Val Loss: 1.8436 Acc: 87.64%
    Time: 47.88s
    Epoch [10 / 20]
    Train Loss: 0.3315 Acc: 97.54%
    Val Loss: 0.3845 Acc: 96.63%
    Time: 47.32s
    Epoch [11 / 20]
    Train Loss: 0.2270 Acc: 97.43%
    Val Loss: 0.5690 Acc: 95.13%
    Time: 47.52s
    Epoch [12 / 20]
    Train Loss: 0.1527 Acc: 98.32%
    Val Loss: 1.2531 Acc: 93.63%
    Time: 47.67s
    Epoch [13 / 20]
    Train Loss: 0.3151 Acc: 98.10%
    Val Loss: 0.6990 Acc: 96.63%
    Time: 48.29s
    Epoch [14 / 20]
    Train Loss: 0.2475 Acc: 98.55%
    Val Loss: 1.0154 Acc: 96.63%
    Time: 47.70s
    Epoch [15 / 20]
    Train Loss: 0.4922 Acc: 96.87%
    Val Loss: 1.5836 Acc: 96.63%
    Time: 47.49s
    Epoch [16 / 20]
    Train Loss: 0.0427 Acc: 99.33%
    Val Loss: 1.0250 Acc: 97.00%
    Time: 49.46s
    Epoch [17 / 20]
    Train Loss: 0.4482 Acc: 98.32%
    Val Loss: 1.9512 Acc: 95.88%
    Time: 47.10s
    Epoch [18 / 20]
    Train Loss: 0.5215 Acc: 97.99%
    Val Loss: 1.1036 Acc: 96.25%
    Time: 47.32s
    Epoch [19 / 20]
    Train Loss: 0.3625 Acc: 98.66%
    Val Loss: 1.2753 Acc: 96.25%
    Time: 47.03s
    Epoch [20 / 20]
    Train Loss: 0.1906 Acc: 98.77%
    Val Loss: 1.1849 Acc: 96.63%
    Time: 47.58s
    VGG19_Transfer í•™ìŠµ ì™„ë£Œ
    Best Validaton Accuracy: 97.00%



```python
test_acc_transfer = test_model(model_transfer, nn.CrossEntropyLoss(), "VGG19_Transfer")
```

    
    ======================================================================
    VGG19_Transfer Test ì‹œì‘
    ======================================================================
    Test Loss: 1.2791
    Test Accuracy: 97.06% (66/68)


## ê²°ê³¼ ì‹œê°í™”


```python
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Loss
axes[0, 0].plot(history_scratch['train_loss'], label='Scratch Train', linewidth=2)
axes[0, 0].plot(history_scratch['val_loss'], label='Scratch Val', linewidth=2)
axes[0, 0].plot(history_transfer['train_loss'], label='Transfer Train', linewidth=2, linestyle='--')
axes[0, 0].plot(history_transfer['val_loss'], label='Transfer Val', linewidth=2, linestyle='--')
axes[0, 0].set_title('Loss Comparison', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Accuracy
axes[0, 1].plot(history_scratch['train_acc'], label='Scratch Train', linewidth=2)
axes[0, 1].plot(history_scratch['val_acc'], label='Scratch Val', linewidth=2)
axes[0, 1].plot(history_transfer['train_acc'], label='Transfer Train', linewidth=2, linestyle='--')
axes[0, 1].plot(history_transfer['val_acc'], label='Transfer Val', linewidth=2, linestyle='--')
axes[0, 1].set_title('Accuracy Comparison', fontsize=14, fontweight='bold')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Accuracy (%)')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Training Time
epochs = range(1, len(history_scratch['epoch_time']) + 1)
axes[1, 0].bar([x - 0.2 for x in epochs], history_scratch['epoch_time'], 
               width=0.4, label='Scratch', alpha=0.8)
axes[1, 0].bar([x + 0.2 for x in epochs], history_transfer['epoch_time'], 
               width=0.4, label='Transfer', alpha=0.8)
axes[1, 0].set_title('Training Time per Epoch', fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Time (seconds)')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3, axis='y')

# Final Performance
categories = ['Train Acc', 'Val Acc']
scratch_metrics = [history_scratch['train_acc'][-1], history_scratch['val_acc'][-1]]
transfer_metrics = [history_transfer['train_acc'][-1], history_transfer['val_acc'][-1]]

x = range(len(categories))
axes[1, 1].bar([i - 0.2 for i in x], scratch_metrics, width=0.4, label='Scratch', alpha=0.8)
axes[1, 1].bar([i + 0.2 for i in x], transfer_metrics, width=0.4, label='Transfer', alpha=0.8)
axes[1, 1].set_title('Final Performance', fontsize=14, fontweight='bold')
axes[1, 1].set_xticks(x)
axes[1, 1].set_xticklabels(categories)
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('vgg19_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
```
 

<img width="1589" height="1190" alt="Image" src="https://github.com/user-attachments/assets/f0321fd8-7eae-47e9-aab7-add03c22e823" />
    

```python
print("\n" + "="*80)
print(" "*25 + "ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
print("="*80)
print(f"{'Model':<20} {'Train Acc':<15} {'Val Acc':<15} {'Test Acc':<15}")
print("-"*80)
print(f"{'VGG19 ì§ì ‘ êµ¬í˜„':<20} "
      f"{history_scratch['train_acc'][-1]:>12.2f}% "
      f"{history_scratch['val_acc'][-1]:>12.2f}% "
      f"{test_acc_scratch:>12.2f}%")
print(f"{'VGG19 ì „ì´í•™ìŠµ':<20} "
      f"{history_transfer['train_acc'][-1]:>12.2f}% "
      f"{history_transfer['val_acc'][-1]:>12.2f}% "
      f"{test_acc_transfer:>12.2f}%")
print("-"*80)
print(f"{'ì •í™•ë„ í–¥ìƒ':<20} "
      f"{history_transfer['train_acc'][-1] - history_scratch['train_acc'][-1]:>+11.2f}%p "
      f"{history_transfer['val_acc'][-1] - history_scratch['val_acc'][-1]:>+11.2f}%p "
      f"{test_acc_transfer - test_acc_scratch:>+11.2f}%p")
print(f"{'í‰ê·  Epoch ì‹œê°„':<20} "
      f"{np.mean(history_scratch['epoch_time']):>11.2f}s "
      f"{np.mean(history_transfer['epoch_time']):>11.2f}s")
print("="*80)

```

    
    ================================================================================
                             ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
    ================================================================================
    Model                Train Acc       Val Acc         Test Acc       
    --------------------------------------------------------------------------------
    VGG19 ì§ì ‘ êµ¬í˜„                 89.61%        90.26%        89.71%
    VGG19 ì „ì´í•™ìŠµ                  98.77%        96.63%        97.06%
    --------------------------------------------------------------------------------
    ì •í™•ë„ í–¥ìƒ                     +9.16%p       +6.37%p       +7.35%p
    í‰ê·  Epoch ì‹œê°„               194.41s       48.93s
    ================================================================================


## ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”


```python
dataloaders['test'] = DataLoader(image_datasets['test'],
                  batch_size=32,
                  shuffle=True,
                  num_workers=2)
```


```python
def visualize_predictions(model, images, labels, model_name='Model', num_images=16):
    model = model.to(device)
    model.eval()

    # ì˜ˆì¸¡
    images = images.to(device)
    with torch.no_grad():
        pred = model(images)
        _, preds = torch.max(pred, 1)

    # CPUë¡œ ì´ë™ 
    # (matplotlib, PIL, cv2 ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” GPU ë°ì´í„°ë¥¼ ì§ì ‘ ì½ì§€ ëª»í•˜ê¸° ë•Œë¬¸)
    images = images.cpu()
    preds = preds.cpu()
    labels = labels.cpu()

    # ì‹œê°í™”
    fig = plt.figure(figsize=(16, 8))
    fig.suptitle(f'{model_name} - Prediction Result', fontsize=20, fontweight='bold')

    num_images = min(num_images, len(images))

    for idx in range(num_images):
        ax = plt.subplot(4, 4, idx + 1)

        # ì´ë¯¸ì§€ denormalize
        # matplotlibë¡œ ê·¸ë¦¼ì„ ê·¸ë¦¬ë ¤ë©´ NumPy í˜•íƒœì—¬ì•¼ í•œë‹¤.
        # transpose: ì°¨ì› ìˆœì„œ ë³€ê²½(C, H, W -> H, W, C)
        img = images[idx].numpy().transpose((1, 2, 0))
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        # ì •ê·œí™” ê³µì‹ ì—­ìˆœ ((Raw - mean) / std)
        img = std * img + mean
        # clip(): 0~1 ì‚¬ì´ë¡œ ê³ ì •
        img = np.clip(img, 0, 1)

        ax.imshow(img)

        # ì˜ˆì¸¡ ê²°ê³¼
        pred_label = class_names[preds[idx]]
        true_label = class_names[labels[idx]]

        # ë§ìœ¼ë©´ ì´ˆë¡ìƒ‰ í‹€ë¦¬ë©´ ë¹¨ê°„ìƒ‰
        color = 'green' if preds[idx] == labels[idx] else 'red'

        ax.set_title(f'Predicted: {pred_label}\nActual: {true_label}',
                    color=color, fontsize=10, fontweight='bold')
        ax.axis('off')

    plt.tight_layout()
    plt.savefig(f'{model_name}_predictions.png', dpi=150, bbox_inches='tight')
    plt.show()
```


```python
print("\n" + "="*70)
print("ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”")
print("="*70 + "\n")

# Test ë°ì´í„°ì—ì„œ ëœë¤ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
dataiter = iter(dataloaders['test'])
images, labels = next(dataiter)

print("VGG19 ì§ì ‘ êµ¬í˜„ ëª¨ë¸ì˜ ì˜ˆì¸¡")
visualize_predictions(model_scratch, images, labels, "VGG19_Scratch", num_images=16)
print("VGG19 ì „ì´í•™ìŠµ ëª¨ë¸ì˜ ì˜ˆì¸¡")
visualize_predictions(model_transfer, images, labels, "VGG19_Transfer", num_images=16)
```

    
    ======================================================================
    ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
    ======================================================================
    
    VGG19 ì§ì ‘ êµ¬í˜„ ëª¨ë¸ì˜ ì˜ˆì¸¡
    
<img width="1262" height="788" alt="Image" src="https://github.com/user-attachments/assets/37a31d59-ad11-42f6-b85a-f645025bb707" />

    VGG19 ì „ì´í•™ìŠµ ëª¨ë¸ì˜ ì˜ˆì¸¡
    
<img width="1262" height="788" alt="Image" src="https://github.com/user-attachments/assets/0a6566b4-9540-4bcd-a5e4-a8ea042d7aaa" />
    
## í˜¼ë™í–‰ë ¬(Confusion Matrix) ì‹œê°í™”


```python
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def plot_confusion_matrix(model, model_name="Model"):
    model = model.to(device)
    model.eval()

    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in dataloaders['test']:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)

    # ì‹œê°í™”
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, # ê° ì…€ì— ìˆ«ì í‘œê¸°
                fmt='d', # ìˆ«ìë¥¼ ì •ìˆ˜(decimal) í˜•ì‹ìœ¼ë¡œ í‘œê¸°
                cmap='Blues',
                xticklabels=class_names, 
                yticklabels=class_names,
                cbar_kws={'label': 'Count'} # ì»¬ëŸ¬ë°”ì— 'Count' ë¼ë²¨ ì¶”ê°€
               )
    
    plt.title(f'{model_name} - Confusion Matrix', fontsize=16, fontweight='bold')
    plt.ylabel('Actual (True Label)', fontsize=12)
    plt.xlabel('Predicted (Predicted Label)', fontsize=12)
    plt.tight_layout()
    plt.savefig(f'{model_name}_confusion_matrix.png', dpi=150, bbox_inches='tight')
    plt.show()

    # Classification Report
    print(f"\n{model_name} - Classification Report:")
    print("="*70)
    print(classification_report(all_labels, all_preds, target_names=class_names))
    print("="*70 + "\n")
```


```python
print("\n" + "="*70)
print("í˜¼ë™ í–‰ë ¬ (Confusion Matrix)")
print("="*70 + "\n")

print("VGG19 ì§ì ‘ êµ¬í˜„")
plot_confusion_matrix(model_scratch, "VGG19_Scratch")

print("VGG19 ì „ì´í•™ìŠµ")
plot_confusion_matrix(model_transfer, "VGG19_Transfer")
```

    
    ======================================================================
    í˜¼ë™ í–‰ë ¬ (Confusion Matrix)
    ======================================================================
    
    VGG19 ì§ì ‘ êµ¬í˜„

<img width="753" height="590" alt="Image" src="https://github.com/user-attachments/assets/4586c7eb-317a-4a15-b6c3-2a52907a3e0c" />
        
    VGG19_Scratch - Classification Report:
    ======================================================================
                  precision    recall  f1-score   support
    
          normal       0.86      0.94      0.90        32
           santa       0.94      0.86      0.90        36
    
        accuracy                           0.90        68
       macro avg       0.90      0.90      0.90        68
    weighted avg       0.90      0.90      0.90        68
    
    ======================================================================
    
    VGG19 ì „ì´í•™ìŠµ

<img width="753" height="590" alt="Image" src="https://github.com/user-attachments/assets/1f231f9e-8008-4efb-84cd-185fb54177d4" />
        
    VGG19_Transfer - Classification Report:
    ======================================================================
                  precision    recall  f1-score   support
    
          normal       0.97      0.97      0.97        32
           santa       0.97      0.97      0.97        36
    
        accuracy                           0.97        68
       macro avg       0.97      0.97      0.97        68
    weighted avg       0.97      0.97      0.97        68
    
    ======================================================================
    
